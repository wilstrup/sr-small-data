{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the QLattice with small data sets\n",
    "\n",
    "In many cases, a researcher has collected a fairly small dataset of a few hundred individuals. In this notebook we apply a systematic approach to test the performance of the QLattice against the usual go-to technologies for fitting and ML.\n",
    "\n",
    "We compare to other **interpretable** models:\n",
    "- Linear models (both with and without LASSO)\n",
    "- Decision Trees\n",
    "\n",
    "And to other **ensemble models** which are more black-box:\n",
    "- Random Forest\n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmlb\n",
    "import pandas as pd\n",
    "import feyn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pmlb.classification_dataset_names)+len(pmlb.regression_dataset_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name in pmlb.regression_dataset_names:\n",
    "#    df = pmlb.fetch_data(name, local_cache_dir=\"/tmp/pmlb_data\")\n",
    "#    print(f\"('{name}', {len(df)}, {len(df.columns)}),\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.DataFrame([\n",
    "('1027_ESL', 488, 5),\n",
    "('1028_SWD', 1000, 11),\n",
    "('1029_LEV', 1000, 5),\n",
    "('1030_ERA', 1000, 5),\n",
    "('1089_USCrime', 47, 14),\n",
    "('1096_FacultySalaries', 50, 5),\n",
    "('1191_BNG_pbc', 1000000, 19),\n",
    "('1193_BNG_lowbwt', 31104, 10),\n",
    "('1196_BNG_pharynx', 1000000, 11),\n",
    "('1199_BNG_echoMonths', 17496, 10),\n",
    "('1201_BNG_breastTumor', 116640, 10),\n",
    "('1203_BNG_pwLinear', 177147, 11),\n",
    "('1595_poker', 1025010, 11),\n",
    "('192_vineyard', 52, 3),\n",
    "('195_auto_price', 159, 16),\n",
    "('197_cpu_act', 8192, 22),\n",
    "('201_pol', 15000, 49),\n",
    "('207_autoPrice', 159, 16),\n",
    "('210_cloud', 108, 6),\n",
    "('215_2dplanes', 40768, 11),\n",
    "('218_house_8L', 22784, 9),\n",
    "('225_puma8NH', 8192, 9),\n",
    "('227_cpu_small', 8192, 13),\n",
    "('228_elusage', 55, 3),\n",
    "('229_pwLinear', 200, 11),\n",
    "('230_machine_cpu', 209, 7),\n",
    "('294_satellite_image', 6435, 37),\n",
    "('344_mv', 40768, 11),\n",
    "('4544_GeographicalOriginalofMusic', 1059, 118),\n",
    "('485_analcatdata_vehicle', 48, 5),\n",
    "('503_wind', 6574, 15),\n",
    "('505_tecator', 240, 125),\n",
    "('519_vinnie', 380, 3),\n",
    "('522_pm10', 500, 8),\n",
    "('523_analcatdata_neavote', 100, 3),\n",
    "('527_analcatdata_election2000', 67, 15),\n",
    "('529_pollen', 3848, 5),\n",
    "('537_houses', 20640, 9),\n",
    "('542_pollution', 60, 16),\n",
    "('547_no2', 500, 8),\n",
    "('556_analcatdata_apnea2', 475, 4),\n",
    "('557_analcatdata_apnea1', 475, 4),\n",
    "('560_bodyfat', 252, 15),\n",
    "('561_cpu', 209, 8),\n",
    "('562_cpu_small', 8192, 13),\n",
    "('564_fried', 40768, 11),\n",
    "('573_cpu_act', 8192, 22),\n",
    "('574_house_16H', 22784, 17),\n",
    "('579_fri_c0_250_5', 250, 6),\n",
    "('581_fri_c3_500_25', 500, 26),\n",
    "('582_fri_c1_500_25', 500, 26),\n",
    "('583_fri_c1_1000_50', 1000, 51),\n",
    "('584_fri_c4_500_25', 500, 26),\n",
    "('586_fri_c3_1000_25', 1000, 26),\n",
    "('588_fri_c4_1000_100', 1000, 101),\n",
    "('589_fri_c2_1000_25', 1000, 26),\n",
    "('590_fri_c0_1000_50', 1000, 51),\n",
    "('591_fri_c1_100_10', 100, 11),\n",
    "('592_fri_c4_1000_25', 1000, 26),\n",
    "('593_fri_c1_1000_10', 1000, 11),\n",
    "('594_fri_c2_100_5', 100, 6),\n",
    "('595_fri_c0_1000_10', 1000, 11),\n",
    "('596_fri_c2_250_5', 250, 6),\n",
    "('597_fri_c2_500_5', 500, 6),\n",
    "('598_fri_c0_1000_25', 1000, 26),\n",
    "('599_fri_c2_1000_5', 1000, 6),\n",
    "('601_fri_c1_250_5', 250, 6),\n",
    "('602_fri_c3_250_10', 250, 11),\n",
    "('603_fri_c0_250_50', 250, 51),\n",
    "('604_fri_c4_500_10', 500, 11),\n",
    "('605_fri_c2_250_25', 250, 26),\n",
    "('606_fri_c2_1000_10', 1000, 11),\n",
    "('607_fri_c4_1000_50', 1000, 51),\n",
    "('608_fri_c3_1000_10', 1000, 11),\n",
    "('609_fri_c0_1000_5', 1000, 6),\n",
    "('611_fri_c3_100_5', 100, 6),\n",
    "('612_fri_c1_1000_5', 1000, 6),\n",
    "('613_fri_c3_250_5', 250, 6),\n",
    "('615_fri_c4_250_10', 250, 11),\n",
    "('616_fri_c4_500_50', 500, 51),\n",
    "('617_fri_c3_500_5', 500, 6),\n",
    "('618_fri_c3_1000_50', 1000, 51),\n",
    "('620_fri_c1_1000_25', 1000, 26),\n",
    "('621_fri_c0_100_10', 100, 11),\n",
    "('622_fri_c2_1000_50', 1000, 51),\n",
    "('623_fri_c4_1000_10', 1000, 11),\n",
    "('624_fri_c0_100_5', 100, 6),\n",
    "('626_fri_c2_500_50', 500, 51),\n",
    "('627_fri_c2_500_10', 500, 11),\n",
    "('628_fri_c3_1000_5', 1000, 6),\n",
    "('631_fri_c1_500_5', 500, 6),\n",
    "('633_fri_c0_500_25', 500, 26),\n",
    "('634_fri_c2_100_10', 100, 11),\n",
    "('635_fri_c0_250_10', 250, 11),\n",
    "('637_fri_c1_500_50', 500, 51),\n",
    "('641_fri_c1_500_10', 500, 11),\n",
    "('643_fri_c2_500_25', 500, 26),\n",
    "('644_fri_c4_250_25', 250, 26),\n",
    "('645_fri_c3_500_50', 500, 51),\n",
    "('646_fri_c3_500_10', 500, 11),\n",
    "('647_fri_c1_250_10', 250, 11),\n",
    "('648_fri_c1_250_50', 250, 51),\n",
    "('649_fri_c0_500_5', 500, 6),\n",
    "('650_fri_c0_500_50', 500, 51),\n",
    "('651_fri_c0_100_25', 100, 26),\n",
    "('653_fri_c0_250_25', 250, 26),\n",
    "('654_fri_c0_500_10', 500, 11),\n",
    "('656_fri_c1_100_5', 100, 6),\n",
    "('657_fri_c2_250_10', 250, 11),\n",
    "('658_fri_c3_250_25', 250, 26),\n",
    "('659_sleuth_ex1714', 47, 8),\n",
    "('663_rabe_266', 120, 3),\n",
    "('665_sleuth_case2002', 147, 7),\n",
    "('666_rmftsa_ladata', 508, 11),\n",
    "('678_visualizing_environmental', 111, 4),\n",
    "('687_sleuth_ex1605', 62, 6),\n",
    "('690_visualizing_galaxy', 323, 5),\n",
    "('695_chatfield_4', 235, 13),\n",
    "('706_sleuth_case1202', 93, 7),\n",
    "('712_chscase_geyser1', 222, 3),\n",
    "('banana', 5300, 3),\n",
    "('titanic', 2201, 4),\n",
    "],\n",
    "columns=[\"name\",\"n\",\"fcount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_datasets = datasets[(datasets[\"n\"]>=1000)]\n",
    "len(chosen_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_datasets.plot.scatter(x=\"n\", y=\"fcount\", loglog=True, ylabel=\"Number of features\", xlabel=\"Number of observations\", figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pmlb_data(name, randomseed, trainsize=100):\n",
    "    df = pmlb.fetch_data(name, local_cache_dir=\"pmlb_data\")\n",
    "    return train_test_split(df,train_size=trainsize, random_state=randomseed)\n",
    "\n",
    "from sklearn import svm, tree, linear_model, ensemble\n",
    "\n",
    "def X(df):\n",
    "    return df.iloc[:,:-1]\n",
    "\n",
    "def y(df):\n",
    "    return df.iloc[:,-1]\n",
    "\n",
    "def fit_and_r2_score(model, train, test):\n",
    "    model.fit(X(train), y(train))\n",
    "    return model.score(X(train), y(train)), model.score(X(test), y(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to the usual suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.DataFrame(columns=[\"dataset\", \"model\", \"randomseed\", \"train_r2\", \"test_r2\"])\n",
    "results = pd.read_csv(\"results-cache-100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = results[~(results[\"model\"].str.startswith(\"ensemble.RandomForestRegressor(n_estimators=25)\"))].reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    linear_model.LinearRegression(),\n",
    "    linear_model.Lasso(alpha=0.01, max_iter=100000),\n",
    "    linear_model.Lasso(alpha=0.05, max_iter=100000),\n",
    "    linear_model.Lasso(alpha=0.10, max_iter=100000),\n",
    "\n",
    "    tree.DecisionTreeRegressor(max_depth=1),\n",
    "    tree.DecisionTreeRegressor(max_depth=2),\n",
    "    tree.DecisionTreeRegressor(max_depth=4),\n",
    "    tree.DecisionTreeRegressor(max_depth=6),\n",
    "    \n",
    "    ensemble.RandomForestRegressor(n_estimators=400),\n",
    "    ensemble.RandomForestRegressor(n_estimators=200),\n",
    "    ensemble.RandomForestRegressor(n_estimators=100),\n",
    "    ensemble.RandomForestRegressor(n_estimators=50),\n",
    "\n",
    "    ensemble.GradientBoostingRegressor(n_estimators=400),\n",
    "    ensemble.GradientBoostingRegressor(n_estimators=200),\n",
    "    ensemble.GradientBoostingRegressor(n_estimators=100),\n",
    "    ensemble.GradientBoostingRegressor(n_estimators=50),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_comparison(name, randomseed):    \n",
    "    global results\n",
    "\n",
    "    print(\"Seed %i, Dataset: %s\"%(randomseed,name), end=\"\")\n",
    "    train, test = get_pmlb_data(name, randomseed)\n",
    "    print(\" ... fetched\", end=\"\")\n",
    "    for m in models:\n",
    "        if ((results[\"dataset\"]==name) & (results[\"model\"]==str(m)) & (results[\"randomseed\"]==randomseed)).any():\n",
    "            # Skip if already run\n",
    "            continue\n",
    "        r2_train, r2_test = fit_and_r2_score(m, train, test)\n",
    "        results = results.append({\"dataset\": name, \"model\": str(m), \"randomseed\": randomseed, \"train_r2\": r2_train, \"test_r2\": r2_test}, ignore_index=True)\n",
    "\n",
    "    print(\" ... and fitted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in chosen_datasets[\"name\"]:\n",
    "    for randomseed in range(0,1):\n",
    "        fit_comparison(name, randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a qgraph for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql = feyn.QLattice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_qgraph(edges, criterion, randomseed):\n",
    "    global results\n",
    "\n",
    "    key = f\"QG-{edges}-{criterion}\"\n",
    "\n",
    "    for name in chosen_datasets[\"name\"]:    \n",
    "        if ((results[\"dataset\"]==name) & (results[\"model\"]==key) & (results[\"randomseed\"]==randomseed)).any():\n",
    "            # Skip if already run\n",
    "            continue\n",
    "\n",
    "        train, test = get_pmlb_data(name, randomseed)\n",
    "        ql.reset(randomseed)\n",
    "        \n",
    "        qg = ql.get_regressor(train.columns, train.columns[-1]).filter(feyn.filters.MaxEdges(edges))\n",
    "    \n",
    "        for _ in range(100):\n",
    "            qg.fit(train, threads=10, criterion=criterion)\n",
    "            print(key, randomseed, name, qg[0]._paramcount)\n",
    "            print(\"Train:\\t\", qg[0].r2_score(train), \"\\nTest:\\t\", qg[0].r2_score(test))\n",
    "            ql.update(qg.best())\n",
    "\n",
    "        for _ in range(1000):\n",
    "            qg[0].fit(train)\n",
    "\n",
    "        results = results.append({\"dataset\": name, \"model\": key, \"randomseed\": randomseed, \"train_r2\": qg[0].r2_score(train), \"test_r2\": qg[0].r2_score(test)}, ignore_index=True)\n",
    "\n",
    "        time.sleep(6) # Protect my poor cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit all QGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for randomseed in range(0,1):\n",
    "    fit_qgraph(11, \"bic\", randomseed=randomseed)\n",
    "    fit_qgraph(11, \"aic\", randomseed=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_among(models=None, datasets=None):\n",
    "    if models is None:\n",
    "        models = results[\"model\"].unique()\n",
    "    if datasets is None:\n",
    "        datasets = results[\"dataset\"].unique()\n",
    "\n",
    "    for dataset in datasets:\n",
    "        subset = results[(results[\"dataset\"] == dataset) & (results[\"test_r2\"]>-1)]\n",
    "        seeds = subset[\"randomseed\"].unique()\n",
    "        for seed in seeds:\n",
    "            subsubset = subset[subset[\"randomseed\"]==seed].sort_values(by=\"test_r2\")\n",
    "            subsubset.plot.barh(x=\"model\", y=[\"test_r2\",\"train_r2\"], title=dataset+\" \"+str(seed),figsize=(8,6))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_among(None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"results-cache-100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_among(models=None, rankpositions = None):\n",
    "    if models is None:\n",
    "        models = results[\"model\"].unique()\n",
    "\n",
    "    if rankpositions is None:\n",
    "        rankpositions = len(models)-1\n",
    "\n",
    "    # Only consider results for the chosen models\n",
    "    res = results[results[\"model\"].isin(models)].sort_values(by=\"test_r2\", ascending=False)\n",
    "    \n",
    "    points = {m: 0 for m in models}\n",
    "    \n",
    "    for name in res[\"dataset\"].unique(): # For each dataset\n",
    "        for seed in res[\"randomseed\"].unique(): # For each seed\n",
    "            subset = res[(res[\"dataset\"]==name) & (res[\"randomseed\"]==seed)]\n",
    "            if len(subset):\n",
    "                for rank in range(rankpositions): # For each rank position\n",
    "                    m = subset.iloc[rank].model\n",
    "                    r2 = subset.iloc[rank].test_r2\n",
    "                    points[m] += rankpositions - rank\n",
    "    return pd.DataFrame(points.items(), columns=[\"model\", \"points\"]).sort_values(by=\"points\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=1).plot.barh(x=\"model\", y=\"points\", label=\"First places\", figsize=(8,6), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=5).plot.barh(x=\"model\", y=\"points\", label=\"Points\", figsize=(8,6), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(\n",
    "    models=[\"QG-11-aic\", \n",
    "            \"GradientBoostingRegressor(n_estimators=400)\", \n",
    "            \"Lasso(alpha=0.1, max_iter=100000)\",\n",
    "            \"RandomForestRegressor(n_estimators=400)\",\n",
    "            \"DecisionTreeRegressor(max_depth=1)\"\n",
    "           ],\n",
    "    rankpositions=1\n",
    ").plot.barh(x=\"model\", y=\"points\", label=\"First places\", figsize=(8,1.6), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(\n",
    "    models=[\"QG-11-aic\", \n",
    "            \"GradientBoostingRegressor(n_estimators=400)\", \n",
    "            \"Lasso(alpha=0.1, max_iter=100000)\",\n",
    "            \"RandomForestRegressor(n_estimators=400)\",\n",
    "            \"DecisionTreeRegressor(max_depth=1)\"\n",
    "           ],\n",
    "    rankpositions=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(\n",
    "    models=[\"QG-11-aic\", \n",
    "            \"Lasso(alpha=0.1, max_iter=100000)\",\n",
    "            \"DecisionTreeRegressor(max_depth=1)\"\n",
    "           ],\n",
    "    rankpositions=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"randomseed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
