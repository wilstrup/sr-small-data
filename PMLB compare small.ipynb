{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the QLattice with small data sets\n",
    "\n",
    "In many cases, a researcher has collected a fairly small dataset of a few hundred individuals. In this notebook we apply a systematic approach to test the performance of the QLattice against the usual go-to technologies for fitting and ML.\n",
    "\n",
    "We compare to other **interpretable** models:\n",
    "- Linear models (both with and without LASSO)\n",
    "- Decision Trees\n",
    "\n",
    "And to other **ensemble models** which are more black-box:\n",
    "- Random Forest\n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Feyn package and QLattice is licensed to Casper Wilstrup, Abzu. By using this software you agree to the terms and conditions which can be found at `https://abzu.ai/eula`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import feyn\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import srsmall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to the usual suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.DataFrame(columns=[\"dataset\", \"model\", \"randomseed\", \"train_r2\", \"test_r2\"])\n",
    "results = pd.read_csv(\"results-cache-wip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, linear_model, ensemble\n",
    "\n",
    "models = [\n",
    "    linear_model.LinearRegression(),\n",
    "#    linear_model.Lasso(alpha=0.01, max_iter=100000),\n",
    "    linear_model.Lasso(alpha=0.05, max_iter=100000),\n",
    "#    linear_model.Lasso(alpha=0.10, max_iter=100000),\n",
    "\n",
    "#    tree.DecisionTreeRegressor(max_depth=1),\n",
    "#    tree.DecisionTreeRegressor(max_depth=2),\n",
    "#    tree.DecisionTreeRegressor(max_depth=4),\n",
    "#    tree.DecisionTreeRegressor(max_depth=6),\n",
    "    \n",
    "#    ensemble.RandomForestRegressor(n_estimators=400),\n",
    "    ensemble.RandomForestRegressor(n_estimators=200),\n",
    "#    ensemble.RandomForestRegressor(n_estimators=100),\n",
    "#    ensemble.RandomForestRegressor(n_estimators=50),\n",
    "\n",
    "#    ensemble.GradientBoostingRegressor(n_estimators=400),\n",
    "    ensemble.GradientBoostingRegressor(n_estimators=200),\n",
    "#    ensemble.GradientBoostingRegressor(n_estimators=100),\n",
    "#    ensemble.GradientBoostingRegressor(n_estimators=50),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(df):\n",
    "    return df.iloc[:,:-1]\n",
    "\n",
    "def y(df):\n",
    "    return df.iloc[:,-1]\n",
    "\n",
    "def fit_comparison(model, name, randomseed):\n",
    "    train, test = srsmall.get_data(name, randomseed)\n",
    "\n",
    "    model.fit(X(train), y(train))\n",
    "\n",
    "    r2_train = model.score(X(train), y(train))\n",
    "    r2_test = model.score(X(test), y(test))\n",
    "    \n",
    "    res = pd.DataFrame([{\"dataset\": name, \"model\": str(model), \"randomseed\": randomseed, \"train_r2\": r2_train, \"test_r2\": r2_test}])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the jobs that need to be run\n",
    "jobargs = []\n",
    "for name in srsmall.small[\"name\"]:\n",
    "    for m in models:\n",
    "        for seed in range(0,5):\n",
    "            if ((results[\"dataset\"]==name) & (results[\"model\"]==str(m)) & (results[\"randomseed\"]==seed)).any():\n",
    "                continue\n",
    "            else:\n",
    "                jobargs.append((m,name,seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 754/754 [00:40<00:00, 18.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a pool of workers to run in parallel\n",
    "with multiprocessing.Pool(processes=6) as pool:\n",
    "    # Map the function to the inputs, distributing the work across multiple processes\n",
    "    reslist = pool.starmap(fit_comparison, tqdm.tqdm(jobargs, total=len(jobargs)), chunksize=1)\n",
    "\n",
    "if (len(reslist)>0):\n",
    "    results = pd.concat([results]+reslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1947214667.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a QModel for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_qmodel(edges, criterion, randomseed):\n",
    "    global results\n",
    "\n",
    "    key = f\"QM-{edges}-{criterion}\"\n",
    "\n",
    "    for name in chosen_datasets[\"name\"]:    \n",
    "        if ((results[\"dataset\"]==name) & (results[\"model\"]==key) & (results[\"randomseed\"]==randomseed)).any():\n",
    "            # Skip if already run\n",
    "            continue\n",
    "\n",
    "        train, test = get_pmlb_data(name, randomseed)\n",
    "        ql = feyn.QLattice(randomseed)\n",
    "            \n",
    "        models = ql.auto_run(train, train.columns[-1], max_complexity=edges, criterion=criterion)\n",
    "        m = models[0]\n",
    "        r = pd.DataFrame([{\"dataset\": name, \"model\": key, \"randomseed\": randomseed, \"train_r2\": m.r2_score(train), \"test_r2\": m.r2_score(test)}])\n",
    "        \n",
    "        results = pd.concat([results, r])\n",
    "        print(key)\n",
    "        \n",
    "        time.sleep(6) # Protect my poor cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit all QModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for randomseed in range(0,5):\n",
    "    fit_qmodel(11, \"bic\", randomseed=randomseed)\n",
    "    fit_qmodel(11, \"aic\", randomseed=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_among(models=None, datasets=None):\n",
    "    if models is None:\n",
    "        models = results[\"model\"].unique()\n",
    "    if datasets is None:\n",
    "        datasets = results[\"dataset\"].unique()\n",
    "\n",
    "    for dataset in datasets:\n",
    "        subset = results[(results[\"dataset\"] == dataset) & (results[\"test_r2\"]>-1)]\n",
    "        seeds = subset[\"randomseed\"].unique()\n",
    "        for seed in seeds:\n",
    "            subsubset = subset[subset[\"randomseed\"]==seed].sort_values(by=\"test_r2\")\n",
    "            subsubset.plot.barh(x=\"model\", y=[\"test_r2\",\"train_r2\"], title=dataset+\" \"+str(seed),figsize=(8,6))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist_among(None,[\"598_fri_c0_1000_25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for name in chosen_datasets[\"name\"]:\n",
    "#    for seed in range(0,5):\n",
    "#        subres = results[(results[\"dataset\"] == name) & (results[\"randomseed\"]==seed) & (results[\"test_r2\"]>-1)].sort_values(by=\"test_r2\")\n",
    "#        if len(subres):\n",
    "#            subres.plot.barh(x=\"model\", y=[\"test_r2\",\"train_r2\"], title=name,figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"results-cache-wip.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_among(models=None, rankpositions = None):\n",
    "    if models is None:\n",
    "        models = results[\"model\"].unique()\n",
    "\n",
    "    if rankpositions is None:\n",
    "        rankpositions = len(models)-1\n",
    "\n",
    "    # Only consider results for the chosen models\n",
    "    res = results[results[\"model\"].isin(models)].sort_values(by=\"test_r2\", ascending=False)\n",
    "    \n",
    "    points = {m: 0 for m in models}\n",
    "    \n",
    "    for name in res[\"dataset\"].unique(): # For each dataset\n",
    "        for seed in res[\"randomseed\"].unique(): # For each seed\n",
    "            subset = res[(res[\"dataset\"]==name) & (res[\"randomseed\"]==seed)]\n",
    "            if len(subset):\n",
    "                for rank in range(rankpositions): # For each rank position\n",
    "                    m = subset.iloc[rank].model\n",
    "                    r2 = subset.iloc[rank].test_r2\n",
    "                    points[m] += rankpositions - rank\n",
    "    return pd.DataFrame(points.items(), columns=[\"model\", \"points\"]).sort_values(by=\"points\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=1).plot.barh(x=\"model\", y=\"points\", label=\"First places\", figsize=(8,6), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=3).plot.barh(x=\"model\", y=\"points\", label=\"Points\", figsize=(8,6), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(rankpositions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_among(\n",
    "    models=[\"QG-11-bic\", \n",
    "            \"GradientBoostingRegressor(n_estimators=400)\", \n",
    "            \"RandomForestRegressor(n_estimators=400)\",\n",
    "            \"Lasso(alpha=0.01, max_iter=100000)\",\n",
    "            \"DecisionTreeRegressor(max_depth=1)\"\n",
    "           ],\n",
    "    rankpositions=5\n",
    ").plot.barh(x=\"model\", y=\"points\", label=\"First places\", figsize=(8,1.6), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rankings to LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_scoring = rank_among(rankpositions=1)\n",
    "second_scoring = rank_among(rankpositions=5)\n",
    "best_scoring = rank_among(\n",
    "    models=[\"QG-11-bic\", \n",
    "            \"Lasso(alpha=0.1, max_iter=100000)\",\n",
    "            \"GradientBoostingRegressor(n_estimators=400)\", \n",
    "            \"RandomForestRegressor(n_estimators=400)\",\n",
    "            \"DecisionTreeRegressor(max_depth=2)\"\n",
    "           ],\n",
    "    rankpositions=1\n",
    ")\n",
    "best_weighted = rank_among(\n",
    "    models=[\"QG-11-bic\", \n",
    "            \"Lasso(alpha=0.1, max_iter=100000)\",\n",
    "            \"GradientBoostingRegressor(n_estimators=400)\", \n",
    "            \"RandomForestRegressor(n_estimators=400)\",\n",
    "            \"DecisionTreeRegressor(max_depth=2)\"\n",
    "           ],\n",
    "    rankpositions=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_scoring[\"First places\"] = first_scoring.points\n",
    "second_scoring[\"Weighted scoring\"] = second_scoring.points\n",
    "best_scoring[\"First places for best\"] = best_scoring.points\n",
    "best_weighted[\"Weighted scoring for best\"] = best_weighted.points\n",
    "\n",
    "\n",
    "first_scoring.index = first_scoring.model\n",
    "second_scoring.index = first_scoring.model\n",
    "best_scoring.index = best_scoring.model\n",
    "best_weighted.index = best_weighted.model\n",
    "\n",
    "first_scoring = first_scoring.drop([\"model\", \"points\"], axis=1)\n",
    "second_scoring = second_scoring.drop([\"model\", \"points\"], axis=1)\n",
    "best_scoring = best_scoring.drop([\"model\", \"points\"], axis=1)\n",
    "best_weighted = best_weighted.drop([\"model\", \"points\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_results = first_scoring.join(second_scoring).join(best_scoring).join(best_weighted).sort_values(by=\"First places\", ascending=False)\n",
    "latex_results[\"First places for best\"] = latex_results[\"First places for best\"].replace(np.nan, 0).astype(int)\n",
    "latex_results[\"First places for best\"] = latex_results[\"First places for best\"].replace(0, \"\")\n",
    "latex_results[\"Weighted scoring for best\"] = latex_results[\"Weighted scoring for best\"].replace(np.nan, 0).astype(int)\n",
    "latex_results[\"Weighted scoring for best\"] = latex_results[\"Weighted scoring for best\"].replace(0, \"\")\n",
    "print(latex_results.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex formatting for the figures that we include in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "# Use Abzu colors\n",
    "\n",
    "abzu_rgba = {\n",
    "    'Dark Jungle Green': (0.11764705882352941, 0.11764705882352941, 0.11764705882352941, 1.0),\n",
    "    'Golden Yellow': (1.0, 1.0, 0.0392156862745098, 1.0),\n",
    "    'Guppie Green': (0.0, 0.9411764705882353, 0.5098039215686274, 1.0),\n",
    "    'Hot Magenta': (1.0, 0.11764705882352941, 0.7843137254901961, 1.0),\n",
    "    'Majorelle Blue': (0.27450980392156865, 0.27450980392156865, 0.9019607843137255, 1.0),\n",
    "    'Robin Egg Blue': (0.0, 0.7843137254901961, 0.7843137254901961, 1.0),\n",
    "    'Safety Orange': (1.0, 0.39215686274509803, 0.0392156862745098, 1.0),\n",
    "    'Spiro Disco Ball': (0.0392156862745098, 0.7058823529411765, 0.9803921568627451, 1.0)\n",
    "}\n",
    "\n",
    "def get_abzu_cmap(cname):\n",
    "    r, g, b, _ = abzu_rgba[cname]\n",
    "    ret = []\n",
    "    for alphaval in np.linspace(0.03, 0.9, 256):\n",
    "        ret.append([r, g, b, alphaval])\n",
    "    return ListedColormap(np.array(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rc('xtick',labelsize=10)\n",
    "mpl.rc('ytick',labelsize=10)\n",
    "\n",
    "mpl.rc('axes',labelsize=15)\n",
    "mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "mpl.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "chosen_datasets.plot.scatter(\n",
    "    x=\"n\",\n",
    "    y=\"fcount\",\n",
    "    loglog=True,\n",
    "    ylabel=\"Number of features\",\n",
    "    xlabel=\"Number of observations\",\n",
    "    color=abzu_rgba['Majorelle Blue'],\n",
    "    s=40,\n",
    "    ax=ax\n",
    ")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"/home/jaan/devel/regressionArticle/jmlr/manuscript/figures/dataset_summary.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for a results figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [\n",
    "    \"QG-11-bic\", \n",
    "    \"GradientBoostingRegressor(n_estimators=400)\", \n",
    "    \"RandomForestRegressor(n_estimators=400)\",\n",
    "    \"Lasso(alpha=0.01, max_iter=100000)\",\n",
    "    \"DecisionTreeRegressor(max_depth=2)\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = results[results.model.isin(best_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'train_r2': 'mean', 'test_r2': 'mean'}\n",
    "sr_results = best_results[best_results.model.apply(lambda x: 'QG' in x)].groupby('dataset').agg(agg_dict)\n",
    "dt_results = best_results[best_results.model.apply(lambda x: 'DecisionTree' in x)].groupby('dataset').agg(agg_dict)\n",
    "gb_results = best_results[best_results.model.apply(lambda x: 'GradientBoosting' in x)].groupby('dataset').agg(agg_dict)\n",
    "rf_results = best_results[best_results.model.apply(lambda x: 'RandomForest' in x)].groupby('dataset').agg(agg_dict)\n",
    "lr_results = best_results[best_results.model.apply(lambda x: 'Lasso' in x)].groupby('dataset').agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{sr_results=}'.split('=')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sr_results.test_r2 < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of negative test R^2 results\n",
    "for name, method_df in {\"sr\": sr_results, \"dt\": dt_results, \"gb\": gb_results, \"rf\": rf_results, \"lr\": lr_results}.items():\n",
    "    print(name, (method_df.test_r2 < 0).sum())\n",
    "    \n",
    "del name\n",
    "del method_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_cloud(df):\n",
    "    return np.vstack([df.train_r2.ravel(), df.test_r2.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr, Yr = np.mgrid[0:1:0.01, 0:1:0.01]\n",
    "all_positions = np.vstack([Xr.ravel(), Yr.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(abzu_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for sax in ax.flatten():\n",
    "    sax.set_ylim(0,1)\n",
    "    sax.set_xlim(0,1)\n",
    "    #sax.set_xlabel(r'Train $R^2$')\n",
    "    #sax.set_ylabel(r'Test $R^2$')\n",
    "    \n",
    "fig.text(0.5, 0.04, r'Training $R^2$', ha='center', size=20)\n",
    "fig.text(0.04, 0.5, r'Validation $R^2$', va='center', rotation='vertical', size=20)\n",
    "\n",
    "scatter_density = np.reshape(gaussian_kde(df_to_cloud(sr_results))(all_positions).T, Xr.shape)\n",
    "ax[0,0].imshow(np.rot90(scatter_density), extent=[0,1,0,1], alpha=.5, cmap=get_abzu_cmap('Spiro Disco Ball'))\n",
    "ax[0,0].plot(np.linspace(0,1,100), np.linspace(0,1,100), ls=\"--\", color=\"black\", alpha=0.4)\n",
    "ax[0,0].scatter(sr_results.train_r2, sr_results.test_r2, color=abzu_rgba['Spiro Disco Ball'])\n",
    "ax[0,0].set_title(r\"\\textbf{(A)} QLattice with BIC\")\n",
    "\n",
    "scatter_density = np.reshape(gaussian_kde(df_to_cloud(lr_results))(all_positions).T, Xr.shape)\n",
    "ax[0,1].imshow(np.rot90(scatter_density), extent=[0,1,0,1], alpha=.5, cmap=get_abzu_cmap('Guppie Green'))\n",
    "ax[0,1].plot(np.linspace(0,1,100), np.linspace(0,1,100), ls=\"--\", color=\"black\", alpha=0.4)\n",
    "ax[0,1].scatter(lr_results.train_r2, lr_results.test_r2, color=abzu_rgba['Guppie Green'])\n",
    "ax[0,1].set_title(r\"\\textbf{(B)} Lasso Regression ($\\alpha=0.1$)\")\n",
    "\n",
    "scatter_density = np.reshape(gaussian_kde(df_to_cloud(dt_results))(all_positions).T, Xr.shape)\n",
    "ax[0,2].imshow(np.rot90(scatter_density), extent=[0,1,0,1], alpha=.5, cmap=get_abzu_cmap('Safety Orange'))\n",
    "ax[0,2].plot(np.linspace(0,1,100), np.linspace(0,1,100), ls=\"--\", color=\"black\", alpha=0.4)\n",
    "ax[0,2].scatter(dt_results.train_r2, dt_results.test_r2, color=abzu_rgba['Safety Orange'])\n",
    "ax[0,2].set_title(r\"\\textbf{(C)} Decision Tree (Max depth 2)\")\n",
    "\n",
    "scatter_density = np.reshape(gaussian_kde(df_to_cloud(gb_results))(all_positions).T, Xr.shape)\n",
    "ax[1,0].imshow(np.rot90(scatter_density), extent=[0,1,0,1], alpha=.5, cmap=get_abzu_cmap('Hot Magenta'))\n",
    "ax[1,0].plot(np.linspace(0,1,100), np.linspace(0,1,100), ls=\"--\", color=\"black\", alpha=0.4)\n",
    "ax[1,0].scatter(gb_results.train_r2, gb_results.test_r2, color=abzu_rgba['Hot Magenta'])\n",
    "ax[1,0].set_title(r\"\\textbf{(D)} Gradient Boosting (400)\")\n",
    "\n",
    "scatter_density = np.reshape(gaussian_kde(df_to_cloud(rf_results))(all_positions).T, Xr.shape)\n",
    "ax[1,1].imshow(np.rot90(scatter_density), extent=[0,1,0,1], alpha=.5, cmap=get_abzu_cmap('Majorelle Blue'))\n",
    "ax[1,1].plot(np.linspace(0,1,100), np.linspace(0,1,100), ls=\"--\", color=\"black\", alpha=0.4)\n",
    "ax[1,1].scatter(rf_results.train_r2, rf_results.test_r2, color=abzu_rgba['Majorelle Blue'])\n",
    "ax[1,1].set_title(r\"\\textbf{(E)} Random Forest (400)\")\n",
    "\n",
    "ax[1,2].set_axis_off()\n",
    "\n",
    "#plt.savefig(\"/home/jaan/devel/regressionArticle/jmlr/manuscript/figures/scatters.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
